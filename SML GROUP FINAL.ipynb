{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13307be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.58 s\n",
      "Wall time: 8.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data exploration\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Data processing\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import mutual_info_classif, VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Experimental setup\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_validate, GridSearchCV, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "#from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "#from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e8ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train, test\n",
    "train = pd.read_csv('./credit_default_train.csv', low_memory=False)\n",
    "test = pd.read_csv('./credit_default_test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85099e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    23\n",
      "int64       2\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18895</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25559.0</td>\n",
       "      <td>26134.0</td>\n",
       "      <td>26715.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25102</td>\n",
       "      <td>390000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140387.0</td>\n",
       "      <td>128112.0</td>\n",
       "      <td>115514.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4548.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28867</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26038.0</td>\n",
       "      <td>28607.0</td>\n",
       "      <td>27997.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1842</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72391.0</td>\n",
       "      <td>61298.0</td>\n",
       "      <td>62193.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2822.0</td>\n",
       "      <td>2336.0</td>\n",
       "      <td>2588.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3371</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id  LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0    18895    70000.0  1.0        3.0       2.0  34.0    0.0    0.0    0.0   \n",
       "1    25102   390000.0  2.0        2.0       2.0  26.0    2.0    2.0    2.0   \n",
       "2    28867    60000.0  1.0        1.0       2.0  27.0    0.0    0.0    0.0   \n",
       "3     1842   140000.0  2.0        2.0       1.0  55.0    0.0    0.0    0.0   \n",
       "4     3371    50000.0  1.0        1.0       2.0  29.0    2.0    2.0    2.0   \n",
       "\n",
       "   PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0    0.0  ...    25559.0    26134.0    26715.0    1700.0    1500.0    2000.0   \n",
       "1    0.0  ...   140387.0   128112.0   115514.0    5000.0    3000.0    5000.0   \n",
       "2    0.0  ...    26038.0    28607.0    27997.0    1378.0    1406.0    3000.0   \n",
       "3    0.0  ...    72391.0    61298.0    62193.0    4200.0    2822.0    2336.0   \n",
       "4    0.0  ...     1047.0        0.0        0.0    3000.0       0.0    1000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0    1000.0    1000.0    2000.0                           0  \n",
       "1    4548.0    4100.0    3300.0                           0  \n",
       "2    3000.0       0.0     923.0                           1  \n",
       "3    2588.0    2250.0    2491.0                           0  \n",
       "4       0.0       0.0       0.0                           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out to check the data\n",
    "print(train.dtypes.value_counts())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bbae654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15586,  4414], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check Target distribution\n",
    "\n",
    "np.bincount(train[\"default.payment.next.month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8800042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code used from Mihn Phan notebooks\n",
    "# General list of variables\n",
    "id_var = [\"cust_id\"]  # ID\n",
    "target_var = [\"default.payment.next.month\"]  # Target get variable\n",
    "predictors = [v for v in train.columns if v not in id_var + target_var]\n",
    "\n",
    "# List of numerical and catergorical variables\n",
    "num_vars = ['LIMIT_BAL', 'AGE',\n",
    "            'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "            'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "cat_vars = ['SEX', 'EDUCATION', 'MARRIAGE',\n",
    "            'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "\n",
    "# Double check the list of variables\n",
    "assert(len(predictors) == len(num_vars) + len(cat_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e61412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop num variables with high missing pct: []\n",
      "Drop cat variables with high missing pct: []\n"
     ]
    }
   ],
   "source": [
    "# Here, we test the effect of dropping variables with high missing percentage (>25%)\n",
    "na_threshold = 0.25\n",
    "\n",
    "# Drop num variables with more than 25% missing values\n",
    "num_na_pct = train[num_vars].isnull().mean()\n",
    "num_vars = num_na_pct[num_na_pct <= na_threshold].index.tolist()\n",
    "print(\"Drop num variables with high missing pct:\", num_na_pct[num_na_pct > na_threshold].tolist())\n",
    "\n",
    "# Drop cat variables with more than 25% missing values\n",
    "cat_na_pct = train[cat_vars].isnull().mean()\n",
    "cat_vars = cat_na_pct[cat_na_pct <= 0.25].index.tolist()\n",
    "print(\"Drop cat variables with high missing pct:\", cat_na_pct[cat_na_pct > na_threshold].tolist())\n",
    "\n",
    "# Update train, test\n",
    "train = train[id_var + num_vars + cat_vars + target_var]\n",
    "# test = test[id_var + num_vars + cat_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b9dad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  2.,  1., nan,  5.,  4.,  6.,  0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"EDUCATION\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88bb7284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\promaninfante\\AppData\\Local\\Temp\\ipykernel_13596\\1420288309.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"EDUCATION\"][train[\"EDUCATION\"].isnull()] = 6\n",
      "C:\\Users\\promaninfante\\AppData\\Local\\Temp\\ipykernel_13596\\1420288309.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"EDUCATION\"][train[\"EDUCATION\"]==6]=5\n",
      "C:\\Users\\promaninfante\\AppData\\Local\\Temp\\ipykernel_13596\\1420288309.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"EDUCATION\"][test[\"EDUCATION\"]==0]=6\n",
      "C:\\Users\\promaninfante\\AppData\\Local\\Temp\\ipykernel_13596\\1420288309.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"EDUCATION\"][test[\"EDUCATION\"].isnull()] = 6\n",
      "C:\\Users\\promaninfante\\AppData\\Local\\Temp\\ipykernel_13596\\1420288309.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"EDUCATION\"][test[\"EDUCATION\"]==6]=5\n"
     ]
    }
   ],
   "source": [
    "#since we have 2 unknown variables, we filled Nas, and merge the 2 unknowns\n",
    "train[\"EDUCATION\"][train[\"EDUCATION\"]==0]=6\n",
    "train[\"EDUCATION\"][train[\"EDUCATION\"].isnull()] = 6\n",
    "train[\"EDUCATION\"][train[\"EDUCATION\"]==6]=5\n",
    "\n",
    "test[\"EDUCATION\"][test[\"EDUCATION\"]==0]=6\n",
    "test[\"EDUCATION\"][test[\"EDUCATION\"].isnull()] = 6\n",
    "test[\"EDUCATION\"][test[\"EDUCATION\"]==6]=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff2d075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  3., nan,  0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"MARRIAGE\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f5c0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\promaninfante\\AppData\\Local\\Temp\\ipykernel_13596\\3117707368.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"MARRIAGE\"][train[\"MARRIAGE\"].isnull()] = 4\n",
      "C:\\Users\\promaninfante\\AppData\\Local\\Temp\\ipykernel_13596\\3117707368.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"MARRIAGE\"][test[\"MARRIAGE\"]==0]=4\n",
      "C:\\Users\\promaninfante\\AppData\\Local\\Temp\\ipykernel_13596\\3117707368.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"MARRIAGE\"][test[\"MARRIAGE\"].isnull()] = 4\n"
     ]
    }
   ],
   "source": [
    "train[\"MARRIAGE\"][train[\"MARRIAGE\"]==0]=4\n",
    "train[\"MARRIAGE\"][train[\"MARRIAGE\"].isnull()] = 4\n",
    "\n",
    "test[\"MARRIAGE\"][test[\"MARRIAGE\"]==0]=4\n",
    "test[\"MARRIAGE\"][test[\"MARRIAGE\"].isnull()] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fb5e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "# Impute missing value using a new category \"-1\"\n",
    "# Note: If the categorical vars are imputed by most_frequent, the indicators should be added\n",
    "train[cat_vars] = train[cat_vars].fillna(-1)\n",
    "test[cat_vars] = test[cat_vars].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d525d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a cat variable\n",
    "v = \"SEX\"\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown=\"error\")\n",
    "enc.fit(pd.concat([train[[v]], test[[v]]], axis=0))\n",
    "#dummy_vars = enc.get_feature_names().tolist()\n",
    "\n",
    "# Transform train, test\n",
    "dummy_vars= []\n",
    "for i in enc.categories_[0]:\n",
    "    dummy_vars.append(v + str(i) + \"_Dummy\")\n",
    "train[dummy_vars] = enc.transform(train[[v]]).toarray()\n",
    "train.drop(columns=v,inplace= True)\n",
    "test[dummy_vars] = enc.transform(test[[v]]).toarray()\n",
    "test.drop(columns=v,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e04910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a cat variable\n",
    "v = \"MARRIAGE\"\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown=\"error\")\n",
    "enc.fit(pd.concat([train[[v]], test[[v]]], axis=0))\n",
    "#dummy_vars = enc.get_feature_names().tolist()\n",
    "\n",
    "# Transform train, test\n",
    "dummy_vars= []\n",
    "for i in enc.categories_[0]:\n",
    "    dummy_vars.append(v + str(i) + \"_Dummy\")\n",
    "train[dummy_vars] = enc.transform(train[[v]]).toarray()\n",
    "train.drop(columns=v,inplace= True)\n",
    "test[dummy_vars] = enc.transform(test[[v]]).toarray()\n",
    "test.drop(columns=v,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30fb1f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a cat variable\n",
    "v = \"EDUCATION\"\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown=\"error\")\n",
    "enc.fit(pd.concat([train[[v]], test[[v]]], axis=0))\n",
    "#dummy_vars = enc.get_feature_names().tolist()\n",
    "\n",
    "# Transform train, test\n",
    "dummy_vars= []\n",
    "for i in enc.categories_[0]:\n",
    "    dummy_vars.append(v + str(i) + \"_Dummy\")\n",
    "train[dummy_vars] = enc.transform(train[[v]]).toarray()\n",
    "train.drop(columns=v,inplace= True)\n",
    "test[dummy_vars] = enc.transform(test[[v]]).toarray()\n",
    "test.drop(columns=v,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32421299",
   "metadata": {},
   "outputs": [],
   "source": [
    "inci_vars = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "for v in inci_vars:\n",
    "# Find the incidence rates per category of a categorical variable\n",
    "    tb = pd.pivot_table(train, values=target_var, index=v, aggfunc=np.mean).reset_index()\n",
    "    icd_var = v + \"_icd\"\n",
    "#     repr_vars.append(icd_var)\n",
    "    tb.columns = [v, icd_var]\n",
    "    # Add the incidence column to train, test\n",
    "    train[icd_var] = pd.merge(train[[v]], tb, on=v)[icd_var]\n",
    "    test[icd_var] = pd.merge(test[[v]], tb, on=v)[icd_var]\n",
    "test.drop(columns=inci_vars,inplace= True)\n",
    "train.drop(columns=inci_vars,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17d0ff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8f0bea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfc6bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List dummary variables to track missing values imputation\n",
    "na_vars = []\n",
    "\n",
    "# Numerical variables\n",
    "# Build the missing value imputor using the mean\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean', add_indicator=True)\n",
    "imp.fit(train[num_vars])\n",
    "\n",
    "# Reconstruct the list of vars + indicators\n",
    "na_vars = na_vars + [num_vars[v] + \"_na\" for v in imp.indicator_.features_]\n",
    "impute_vars = num_vars + na_vars\n",
    "\n",
    "# Apply on train, test\n",
    "train[impute_vars] = pd.DataFrame(imp.transform(train[num_vars]), columns=impute_vars)\n",
    "test[impute_vars] = pd.DataFrame(imp.transform(test[num_vars]), columns=impute_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ed2c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIMIT_BAL has # outliers on train, test : 92 [ 0.46 % ] 37 [ 0.37 % ]\n",
      "AGE has # outliers on train, test : 89 [ 0.44 % ] 51 [ 0.51 % ]\n",
      "BILL_AMT1 has # outliers on train, test : 458 [ 2.29 % ] 225 [ 2.25 % ]\n",
      "BILL_AMT2 has # outliers on train, test : 457 [ 2.28 % ] 208 [ 2.08 % ]\n",
      "BILL_AMT3 has # outliers on train, test : 439 [ 2.2 % ] 220 [ 2.2 % ]\n",
      "BILL_AMT4 has # outliers on train, test : 454 [ 2.27 % ] 228 [ 2.28 % ]\n",
      "BILL_AMT5 has # outliers on train, test : 434 [ 2.17 % ] 216 [ 2.16 % ]\n",
      "BILL_AMT6 has # outliers on train, test : 437 [ 2.18 % ] 212 [ 2.12 % ]\n",
      "PAY_AMT1 has # outliers on train, test : 284 [ 1.42 % ] 159 [ 1.59 % ]\n",
      "PAY_AMT2 has # outliers on train, test : 199 [ 1.0 % ] 118 [ 1.18 % ]\n",
      "PAY_AMT3 has # outliers on train, test : 253 [ 1.26 % ] 111 [ 1.11 % ]\n",
      "PAY_AMT4 has # outliers on train, test : 266 [ 1.33 % ] 133 [ 1.33 % ]\n",
      "PAY_AMT5 has # outliers on train, test : 278 [ 1.39 % ] 132 [ 1.32 % ]\n",
      "PAY_AMT6 has # outliers on train, test : 302 [ 1.51 % ] 131 [ 1.31 % ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the outliers on train, test\n",
    "for v in num_vars:\n",
    "    # Calculate the boundaries on train [mean-3*sd, mean+3*sd]\n",
    "    mu = np.mean(train[v])\n",
    "    sd = np.std(train[v])\n",
    "    lower = mu - 3*sd\n",
    "    upper = mu + 3*sd\n",
    "    # Check outliers using the boundaries\n",
    "    train_out = (train[v] < lower) | (train[v] > upper)\n",
    "    test_out = (test[v] < lower) | (test[v] > upper)\n",
    "    if np.sum(train_out) + np.sum(test_out) > 0:\n",
    "        print(v, \"has # outliers on train, test :\",\n",
    "              np.sum(train_out), \"[\", np.round(100*np.mean(train_out), 2), \"% ]\",\n",
    "              np.sum(test_out), \"[\", np.round(100*np.mean(test_out), 2), \"% ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "321fec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in num_vars:\n",
    "    winsorize(train[j], limits=[0.05, 0.05])\n",
    "    winsorize(test[j], limits=[0.05, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5fe0df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in num_vars:\n",
    "        # Build the normalizer on train\n",
    "    scaler = MinMaxScaler().fit(train[[v]])\n",
    "        # Apply on train, test\n",
    "    train[v] = scaler.transform(train[[v]])\n",
    "    test[v] = scaler.transform(test[[v]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a70309d",
   "metadata": {},
   "source": [
    "### MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ffe10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and set\n",
    "X, y = train.drop([\"cust_id\", \"default.payment.next.month\"], axis=1), train[\"default.payment.next.month\"]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7c284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define which models are best suited\n",
    "log_reg_params = [{\"C\":0.01}, {\"C\":0.1}, {\"C\":1}, {\"C\":10}]\n",
    "dec_tree_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "rand_for_params = [{\"criterion\": \"gini\"}, {\"criterion\": \"entropy\"}]\n",
    "kneighbors_params = [{\"n_neighbors\":3}, {\"n_neighbors\":5}]\n",
    "naive_bayes_params = [{}]\n",
    "svc_params = [{\"C\":0.01}, {\"C\":0.1}, {\"C\":1}, {\"C\":10}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b61b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelclasses = [\n",
    "    [\"log regression\", LogisticRegression, log_reg_params],\n",
    "    [\"decision tree\", DecisionTreeClassifier, dec_tree_params],\n",
    "    [\"random forest\", RandomForestClassifier, rand_for_params],\n",
    "    [\"k neighbors\", KNeighborsClassifier, kneighbors_params],\n",
    "    [\"naive bayes\", GaussianNB, naive_bayes_params],\n",
    "    [\"support vector machines\", SVC, svc_params]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "insights = []\n",
    "for modelname, Model, params_list in modelclasses:\n",
    "    for params in params_list:\n",
    "        model = Model(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_val, y_val)\n",
    "        insights.append((modelname, model, params, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ccf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insights.sort(key=lambda x:x[-1], reverse=True)\n",
    "for modelname, model, params, score in insights:\n",
    "    print(modelname, params, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a2b9d",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eec26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg =LogisticRegression(random_state=123, max_iter=500, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb587389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation on Log Reg\n",
    "cv_lr = cross_val_score(logreg, X, y, scoring=\"roc_auc\", cv=3,n_jobs= -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b23103",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_lr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa700c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "# define model\n",
    "model = LogisticRegression()\n",
    "# define evaluation\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "# define search space\n",
    "grid = dict()\n",
    "grid['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "grid['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "grid['C'] = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "# define search\n",
    "Lrgrid = GridSearchCV(model, grid, scoring='roc_auc', n_jobs=-2, cv=cv)\n",
    "# execute search\n",
    "Lrgrid = Lrgrid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_pred_prob = Lrgrid.predict_proba(X_val)[:,1]\n",
    "log_pred_prob_train = Lrgrid.predict_proba(X_train)[:,1]\n",
    "\n",
    "log_pred = Lrgrid.predict(X_val)\n",
    "log_pred_train = Lrgrid.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f5b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_val = accuracy_score(y_val, log_pred)\n",
    "accuracy_train = accuracy_score(y_train, log_pred_train)\n",
    "print(f\"Accuracy Train: {accuracy_train} \\nAccuracy Val: {accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78bdc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_val = roc_auc_score(y_val, log_pred_prob)\n",
    "auc_train = roc_auc_score(y_train, log_pred_prob_train)\n",
    "\n",
    "print(f\"AUC Train: {auc_train} \\nAUC Val: {auc_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac52d8d",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad1e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['linear','rbf',\"poly\",'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baeed08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517be061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "grid = GridSearchCV(SVC(),param_grid,refit = True, verbose=2, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will take ages to run\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40f3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(random_state=123, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_svc = cross_val_score(svc, X, y, scoring=\"roc_auc\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a562e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_svc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b95d6e",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db934928",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27806bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8,9,10],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c67a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5,n_jobs= -2)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcadab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba34737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion=\"gini\", n_estimators=200, random_state=42, max_depth=10,max_features = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db9f5bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpred = rf.predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpred_train = rf.predict_proba(X_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82532fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train, rfpred_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237bf715",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_val, rfpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4713bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "forest_importances = pd.Series(importances, index=X_train.columns)\n",
    "forest_importances = forest_importances[forest_importances>= forest_importances.mean()]\n",
    "forest_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74566d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar( ax=ax)\n",
    "ax.set_title(\"Feature importances using RF\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12752f01",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec6e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e81591",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'learning_rate': [0.01, 0.02, 0.05]    \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e3538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "folds = 3\n",
    "param_comb = 100\n",
    "\n",
    "#Gridsearch\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=1000, objective='binary:logistic',\n",
    "                    silent=True, nthread=6, tree_method='gpu_hist', eval_metric='auc')\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=-2, cv=skf.split(X_train,y_train), verbose=3, random_state=1001 )\n",
    "\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea38fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a5e0f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\recomtools\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "x_grad = XGBClassifier(subsample = 0.6, min_child_weight =  1, max_depth= 10,learning_rate = 0.01,gamma= 5,colsample_bytree= 0.6, eval_metric='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "466897d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\recomtools\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\recomtools\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6,\n",
       "              enable_categorical=False, eval_metric='auc', gamma=5, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=0.6, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_grad.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77552364",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xcgb_pred_prob = x_grad.predict_proba(X_val)[:,1]\n",
    "xcgb_pred_prob_train = x_grad.predict_proba(X_train)[:,1]\n",
    "\n",
    "xcgb_pred = x_grad.predict(X_val)\n",
    "xcgb_pred_train = x_grad.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65b11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_val = accuracy_score(y_val, xcgb_pred)\n",
    "accuracy_train = accuracy_score(y_train, xcgb_pred_train)\n",
    "print(f\"Accuracy Train: {accuracy_train} \\nAccuracy Val: {accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d562e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_val = roc_auc_score(y_val, xcgb_pred_prob)\n",
    "auc_train = roc_auc_score(y_train, xcgb_pred_prob_train)\n",
    "\n",
    "print(f\"AUC Train: {auc_train} \\nAUC Val: {auc_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebaf325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_importances = x_grad.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gb_importances = pd.Series(xgb_importances, index=X_train.columns)\n",
    "gb_importances = gb_importances[gb_importances>= gb_importances.mean()]\n",
    "gb_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74831bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "gb_importances.plot.bar( ax=ax)\n",
    "ax.set_title(\"Feature importances using XGBoosting\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf147a6",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10689d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "scoring= ['roc_auc']\n",
    "parameters = {#'nthread':[3,4], #when use hyperthread, xgboost may become slower\n",
    "               \"criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "              \"loss\":[\"deviance\",\"exponential\"],\n",
    "              \"max_features\":[\"log2\",\"sqrt\"],\n",
    "              'learning_rate': [0.01,0.05,0.1,1,0.5], #so called `eta` value\n",
    "              'max_depth': [3,4,5],\n",
    "              'min_samples_leaf': [4,5,6],\n",
    "\n",
    "              'subsample': [0.6,0.7,0.8],\n",
    "              'n_estimators': [50,100,150,200]#number of trees, change it to 1000 for better results\n",
    "              \n",
    "\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f39fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(GradientBoostingClassifier(), parameters,scoring=scoring,refit=False,cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ad95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba796a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92261636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimator.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bdb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pred_prob = gb.predict_proba(X_val)[:,1]\n",
    "gb_pred_prob_train = gb.predict_proba(X_train)[:,1]\n",
    "\n",
    "gb_pred = gb.predict(X_val)\n",
    "gb_pred_train = gb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_val = accuracy_score(y_val, gb_pred)\n",
    "accuracy_train = accuracy_score(y_train, gb_pred_train)\n",
    "print(f\"Accuracy Train: {accuracy_train} \\nAccuracy Val: {accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb20bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_val = roc_auc_score(y_val, gb_pred_prob)\n",
    "auc_train = roc_auc_score(y_train, gb_pred_prob_train)\n",
    "\n",
    "print(f\"AUC Train: {auc_train} \\nAUC Val: {auc_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82c6ca",
   "metadata": {},
   "source": [
    "##### Cross Validation Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939035df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_gb = cross_val_score(gb, X, y, scoring=\"roc_auc\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_gb.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a93225",
   "metadata": {},
   "source": [
    "#### NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce6faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff504ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  '''\n",
    "  Args:\n",
    "    hp - Keras tuner object\n",
    "  '''\n",
    "  # Initialize the Sequential API and start stacking the layers\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(46, 1)))\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu', name='dense_1'))\n",
    "  # Add next layers\n",
    "  model.add(keras.layers.Dropout(0.2))\n",
    "  model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "#https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt\n",
    "\n",
    "# Instantiate the tuner\n",
    "tuner = kt.Hyperband(model_builder, # the hypermodel\n",
    "                     objective='val_accuracy', # objective to optimize\n",
    "max_epochs=10,\n",
    "factor=3, # factor which you have seen above \n",
    "directory='dir', # directory to save logs \n",
    "project_name='khyperband')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b553029",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
    "# Perform hypertuning\n",
    "tuner.search(X_train, y_train, epochs=10, validation_split=0.3, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4992286",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp=tuner.get_best_hyperparameters()[0]\n",
    "# Build the model with the optimal hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cd3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_model = tuner.hypermodel.build(best_hps)\n",
    "h_model.summary()\n",
    "h_model.fit(X_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_pred_prob = h_model.predict(X_val)[:,1]\n",
    "NN_pred_prob_train = h_model.predict(X_train)[:,1]\n",
    "auc_val = roc_auc_score(y_val, NN_pred_prob)\n",
    "auc_train = roc_auc_score(y_train, NN_pred_prob_train)\n",
    "\n",
    "print(f\"AUC Train: {auc_train} \\nAUC Val: {auc_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ce7c1",
   "metadata": {},
   "source": [
    "#### HYBRID MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb35753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "763430bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\recomtools\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\tools\\Anaconda3\\envs\\recomtools\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "hybrid = VotingClassifier(estimators=[('rf', rf), ('x_grad', x_grad)], voting='soft')\n",
    "hybrid = hybrid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "218f25fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\recomtools\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "C:\\tools\\Anaconda3\\envs\\recomtools\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "C:\\tools\\Anaconda3\\envs\\recomtools\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "C:\\tools\\Anaconda3\\envs\\recomtools\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "hybrid_pred_prob = hybrid.predict_proba(X_val)[:,1]\n",
    "hybrid_prob_train = hybrid.predict_proba(X_train)[:,1]\n",
    "\n",
    "hybrid_pred = hybrid.predict(X_val)\n",
    "hybrid_pred_train = hybrid.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "459e94fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train: 0.816 \n",
      "Accuracy Val: 0.7885\n"
     ]
    }
   ],
   "source": [
    "accuracy_val = accuracy_score(y_val, hybrid_pred)\n",
    "accuracy_train = accuracy_score(y_train, hybrid_pred_train)\n",
    "print(f\"Accuracy Train: {accuracy_train} \\nAccuracy Val: {accuracy_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08fe3948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Train: 0.8834097751832439 \n",
      "AUC Val: 0.730128085434655\n"
     ]
    }
   ],
   "source": [
    "auc_val = roc_auc_score(y_val, hybrid_pred_prob)\n",
    "auc_train = roc_auc_score(y_train, hybrid_prob_train)\n",
    "\n",
    "print(f\"AUC Train: {auc_train} \\nAUC Val: {auc_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6322b9a5",
   "metadata": {},
   "source": [
    "##### Plotting ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9cf429",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_roc_curve(gb, X_val, y_val)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5bb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ba385c",
   "metadata": {},
   "source": [
    "#### Predicting Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2994ee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=  test.drop([\"cust_id\"], axis=1)\n",
    "rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39a5ba94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\recomtools\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "C:\\Users\\promaninfante\\AppData\\Local\\Temp\\ipykernel_13596\\3237322588.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_predict[\"default.payment.next.month\"] = hybrid.predict_proba(X_test)[:,1]\n"
     ]
    }
   ],
   "source": [
    "test_predict = test[[\"cust_id\"]]\n",
    "test_predict[\"default.payment.next.month\"] = hybrid.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a5a3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sorted = test_predict.sort_values(by=\"default.payment.next.month\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b8099",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee052627",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original = pd.read_csv('./credit_default_test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d758b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_cust = test_sorted[test_sorted[\"default.payment.next.month\"]>=0.41][\"cust_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d418aa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_default = test_original[test_original[\"cust_id\"].isin(top_10_cust)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2272be90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\promaninfante\\AppData\\Local\\Temp\\ipykernel_13596\\2763052020.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  top_10_default[\"age_group\"] = (top_10_default[\"AGE\"]//10)*10\n"
     ]
    }
   ],
   "source": [
    "top_10_default[\"age_group\"] = (top_10_default[\"AGE\"]//10)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "305376db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_original[\"age_group\"] = (test_original[\"AGE\"]//10)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1f874e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18847</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39526.0</td>\n",
       "      <td>41346.0</td>\n",
       "      <td>40630.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10205</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>269278.0</td>\n",
       "      <td>269278.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3355.0</td>\n",
       "      <td>5688.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27114</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45290.0</td>\n",
       "      <td>48322.0</td>\n",
       "      <td>49094.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>41</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19492.0</td>\n",
       "      <td>19888.0</td>\n",
       "      <td>14087.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>25759</td>\n",
       "      <td>460000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>27011</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29499.0</td>\n",
       "      <td>30124.0</td>\n",
       "      <td>26855.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>26815</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13923.0</td>\n",
       "      <td>13405.0</td>\n",
       "      <td>13683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>2726.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>643.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>3608</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15116.0</td>\n",
       "      <td>14582.0</td>\n",
       "      <td>14206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2230.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>13758</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>19212</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18848.0</td>\n",
       "      <td>30190.0</td>\n",
       "      <td>19664.0</td>\n",
       "      <td>7403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>990 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id  LIMIT_BAL  SEX  EDUCATION  MARRIAGE   AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0       18847   130000.0  1.0        1.0       2.0  33.0    1.0    2.0    2.0   \n",
       "5       10205   400000.0  2.0        1.0       1.0  44.0    4.0    3.0    2.0   \n",
       "10      27114    50000.0  2.0        2.0       1.0  34.0    2.0    2.0    2.0   \n",
       "17         41    20000.0  1.0        3.0       2.0  28.0    1.0    2.0    2.0   \n",
       "21      25759   460000.0  1.0        1.0       1.0  39.0    2.0    2.0    5.0   \n",
       "...       ...        ...  ...        ...       ...   ...    ...    ...    ...   \n",
       "9970    27011    30000.0  2.0        2.0       1.0  67.0    2.0    2.0    0.0   \n",
       "9976    26815    20000.0  1.0        2.0       2.0  42.0    1.0    2.0    0.0   \n",
       "9979     3608    20000.0  1.0        3.0       1.0  53.0    3.0    4.0    3.0   \n",
       "9983    13758   360000.0  1.0        1.0       1.0  32.0   -1.0   -1.0   -2.0   \n",
       "9985    19212    20000.0  1.0        2.0       2.0  23.0    0.0    0.0    2.0   \n",
       "\n",
       "      PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0       2.0  ...    39526.0    41346.0    40630.0       0.0    6000.0   \n",
       "5       0.0  ...   269278.0   269278.0     1976.0       0.0       0.0   \n",
       "10      2.0  ...    45290.0    48322.0    49094.0    2000.0    1700.0   \n",
       "17      2.0  ...    19492.0    19888.0    14087.0       0.0    2860.0   \n",
       "21      5.0  ...     2495.0     2495.0     2495.0       0.0       0.0   \n",
       "...     ...  ...        ...        ...        ...       ...       ...   \n",
       "9970    0.0  ...    29499.0    30124.0    26855.0       0.0    1500.0   \n",
       "9976    0.0  ...    13923.0    13405.0    13683.0       0.0    1600.0   \n",
       "9979    2.0  ...    15116.0    14582.0    14206.0       0.0       0.0   \n",
       "9983   -2.0  ...        0.0        0.0        0.0       0.0       0.0   \n",
       "9985    0.0  ...    18848.0    30190.0    19664.0    7403.0       0.0   \n",
       "\n",
       "      PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  age_group  \n",
       "0          0.0    3000.0    1000.0    1100.0       30.0  \n",
       "5        150.0       0.0    3355.0    5688.0       40.0  \n",
       "10         0.0    3760.0    1700.0       0.0       30.0  \n",
       "17         0.0     549.0     441.0     502.0       20.0  \n",
       "21         0.0       0.0       0.0       0.0       30.0  \n",
       "...        ...       ...       ...       ...        ...  \n",
       "9970    2182.0    1200.0       0.0    2302.0       60.0  \n",
       "9976    2726.0       0.0     643.0     646.0       40.0  \n",
       "9979    1200.0       0.0       0.0    2230.0       50.0  \n",
       "9983       0.0       0.0       0.0       0.0       30.0  \n",
       "9985     820.0    1025.0    1113.0     104.0       20.0  \n",
       "\n",
       "[990 rows x 25 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be6eb323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group  SEX\n",
       "20.0       1.0    0.140301\n",
       "           2.0    0.101435\n",
       "30.0       1.0    0.086635\n",
       "           2.0    0.071141\n",
       "40.0       1.0    0.117965\n",
       "           2.0    0.089438\n",
       "50.0       1.0    0.126761\n",
       "           2.0    0.126263\n",
       "60.0       1.0    0.160714\n",
       "           2.0    0.115385\n",
       "70.0       1.0         NaN\n",
       "           2.0         NaN\n",
       "Name: cust_id, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_default.groupby([\"age_group\", \"SEX\"])[\"cust_id\"].count()/test_original.groupby([\"age_group\",\"SEX\"])[\"cust_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9344cd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MARRIAGE\n",
       "0.0      2\n",
       "1.0    485\n",
       "2.0    484\n",
       "3.0      9\n",
       "Name: cust_id, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_default.groupby([\"MARRIAGE\"])[\"cust_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "585d4bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_group  SEX\n",
       "20.0       1.0    149\n",
       "           2.0    205\n",
       "30.0       1.0    129\n",
       "           2.0    159\n",
       "40.0       1.0    109\n",
       "           2.0    105\n",
       "50.0       1.0     45\n",
       "           2.0     50\n",
       "60.0       1.0      9\n",
       "           2.0      6\n",
       "Name: cust_id, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_default.groupby([\"age_group\",\"SEX\"])[\"cust_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "22b295b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEX\n",
       "1.0    3936\n",
       "2.0    5953\n",
       "Name: cust_id, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_original.groupby([\"SEX\"])[\"cust_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e83945",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict.to_csv(\"./predict_rf.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba6500",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
